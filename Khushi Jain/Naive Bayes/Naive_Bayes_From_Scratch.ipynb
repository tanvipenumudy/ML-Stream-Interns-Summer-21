{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Naive_Bayes_From_Scratch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2gUALxIPBws"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "import random\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anoXZlS6Tj8x"
      },
      "source": [
        "# Gaussian Naive Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIRT9JX5A3g3"
      },
      "source": [
        "## Train test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tfYRcVtA5bS"
      },
      "source": [
        "def train_test_split(df, test_size):\n",
        "\n",
        "  if isinstance(test_size, float):\n",
        "    test_size = round(test_size*len(df))\n",
        "  \n",
        "  indices = df.index.tolist() # random.sample takes list, set, dictionary\n",
        "  test_indices = random.sample(population=indices, k=test_size)\n",
        "\n",
        "  test = df.loc[test_indices]\n",
        "  train = df.drop(test_indices)\n",
        "\n",
        "  return train, test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rW28gtRhXGxT"
      },
      "source": [
        "## Calculate Prior Probabilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4hlvd5nV44e"
      },
      "source": [
        "def calculate_prior_probabilities(df):\n",
        "\n",
        "  prior_probabilities = df.groupby(by = 'target').apply(lambda x: len(x)/len(df))\n",
        "\n",
        "  return np.log(prior_probabilities).values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42ONfI_tkg-J"
      },
      "source": [
        "# calculate_prior_probabilities(df)\n",
        "\n",
        "# [Prior_probability(setosa), Prior_probability(versicolor), Prior_probability(virginica)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCVsNsy-ZC3c"
      },
      "source": [
        "## Find mean, variance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhBDIS0JZCav"
      },
      "source": [
        "def return_statistics(df):\n",
        "\n",
        "  mean = df.groupby(by='target').apply(lambda x: x.mean(axis=0))\n",
        "  variance = df.groupby(by='target').apply(lambda x: x.var(axis=0))\n",
        "\n",
        "  return (mean.values, variance.values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z91Ei4T-fwZn"
      },
      "source": [
        "# mean, variance = return_statistics(df)\n",
        "# print(mean)\n",
        "# print(variance)\n",
        "\n",
        "#             s_l  s_w  p_l  p_w\n",
        "# setosa\n",
        "# versicolor\n",
        "# virginica"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWXFmsvcXY9v"
      },
      "source": [
        "## Find Gaussian Probability density"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qnu1CIs-XB6-"
      },
      "source": [
        "# P(x=12 | 'setosa')\n",
        "\n",
        "def calculate_probability_density(mean, variance, x):\n",
        "\n",
        "  probability_density = (1 / np.sqrt(2*np.pi*variance) ) * np.exp( (-(x - mean)**2)  / ( 2*variance ) )\n",
        "\n",
        "  return probability_density"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lgh-OaJ_05Ln"
      },
      "source": [
        "## Posterior Probabilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ueSjXpbX-3r"
      },
      "source": [
        "def calculate_posterior_probabilities(df_row, mean, variance, n_unique_labels, n_cols):\n",
        "  \n",
        "  posterior_probabilities = []\n",
        "  \n",
        "  # calculate probabilities wrt each label to find max\n",
        "  for i in range(n_unique_labels):\n",
        "    posterior = 0\n",
        "\n",
        "    # for each feature\n",
        "    for j in range(n_cols):\n",
        "      posterior += np.log(calculate_probability_density(mean[i][j], variance[i][j], df_row[j]))\n",
        "    posterior_probabilities.append(posterior)\n",
        "  \n",
        "  return posterior_probabilities"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loqxsXX1X-yB"
      },
      "source": [
        "# calculate_posterior_probabilities()\n",
        "\n",
        "# [posterior_probability['setosa'], posterior_probability['versicolor'], posterior_probability['virginica']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6LKgZzh00jz"
      },
      "source": [
        "## Fit model on training dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ma7rUVppX-vt"
      },
      "source": [
        "def NBA_fit(df):\n",
        "\n",
        "  n_cols = len(df.columns)-1\n",
        "  unique_labels = df['target'].unique()\n",
        "  n_unique_labels = len(unique_labels)\n",
        "\n",
        "  mean, variance = return_statistics(df)\n",
        "  prior_probabilities = calculate_prior_probabilities(df) # returns log\n",
        "\n",
        "  return {\n",
        "      'n_cols': n_cols,\n",
        "      'unique_labels': unique_labels,\n",
        "      'n_unique_labels': n_unique_labels,\n",
        "      'mean': mean,\n",
        "      'variance': variance,\n",
        "      'prior_probabilities': prior_probabilities\n",
        "  }\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xz3fxWBiX-tL"
      },
      "source": [
        "# nba = NBA_fit(df)\n",
        "\n",
        "# Returns a dictonary containing statistical and other important info"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZM6GHJtb0yFz"
      },
      "source": [
        "## Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UFBuSjbxiOI"
      },
      "source": [
        "def predict(test_df, nba):\n",
        "\n",
        "  predictions = []\n",
        "  for i in range(len(test_df)):\n",
        "\n",
        "    prior = nba['prior_probabilities']\n",
        "    posterior = calculate_posterior_probabilities(test_df.iloc[i, :-1], nba['mean'], nba['variance'], nba['n_unique_labels'], nba['n_cols'])  # returns log\n",
        "    probabilities = prior + posterior\n",
        "    # one with max prob will be the output \n",
        "    mx_idx = np.argmax(probabilities)\n",
        "\n",
        "    predictions.append(nba['unique_labels'][mx_idx])  # add log values\n",
        "\n",
        "  return predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLZrR1joX-rG"
      },
      "source": [
        "# predictions = predict(test_df, nba)\n",
        "\n",
        "# returns label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clVNrTLV809l"
      },
      "source": [
        "## Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "IEjVfRkhTO_v",
        "outputId": "ab0e92a0-f7af-49cd-bbeb-a0c45da02bba"
      },
      "source": [
        "df = sns.load_dataset('iris')\n",
        "df_copy = df.copy()\n",
        "df.rename(columns={'species': 'target'}, inplace = True)\n",
        "\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal_length</th>\n",
              "      <th>sepal_width</th>\n",
              "      <th>petal_length</th>\n",
              "      <th>petal_width</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sepal_length  sepal_width  petal_length  petal_width  target\n",
              "0           5.1          3.5           1.4          0.2  setosa\n",
              "1           4.9          3.0           1.4          0.2  setosa\n",
              "2           4.7          3.2           1.3          0.2  setosa\n",
              "3           4.6          3.1           1.5          0.2  setosa\n",
              "4           5.0          3.6           1.4          0.2  setosa"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYAcCD9xIa6P"
      },
      "source": [
        "No null values present"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzcWouD5AZoX",
        "outputId": "c28acbf3-5797-4d45-cf8c-4f7ccf1f1954"
      },
      "source": [
        "# train test split\n",
        "train_df, test_df = train_test_split(df, 0.2)\n",
        "\n",
        "# fit model\n",
        "nba = NBA_fit(train_df)\n",
        "\n",
        "# make predictions\n",
        "predictions = predict(test_df, nba)\n",
        "\n",
        "# accuracy\n",
        "accuracy = len(test_df.loc[predictions == test_df['target']])/len(test_df) * 100\n",
        "accuracy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "96.66666666666667"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-fzSmYcnH1p"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sv_IDmtnHzV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}